services:
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: youtube_sentiment_api
    ports:
      - "8000:8000"
    # env_file path to look one directory up (project root)
    env_file:
      - ../.env
    environment:
      # Explicitly override the MLFLOW_TRACKING_URI for the container to use
      # the internal Docker service name (mlflow), good for connection issues.
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      # Code path mounting (relative to docker/ folder)
      - ../app:/app/app
      - ../src:/app/src
      # Add dependency files for uvicorn's --reload to function correctly
      - ../pyproject.toml:/app/pyproject.toml
      - ../uv.lock:/app/uv.lock
      # NOTE: Removed mounts for /data, /models, /mlruns, /mlflow.db
      # The API must load the model from the MLflow Server, not the local file system.
    command: >
      uv run uvicorn app.main:app
      --host 0.0.0.0 --port 8000 --reload
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - mlflow

  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: mlflow_server
    ports:
      - "5000:5000"
    command: >
      mlflow server
      --backend-store-uri sqlite:////app/mlflow.db
      --default-artifact-root /app/mlruns
      --host 0.0.0.0
      --port 5000
      --allowed-hosts *
    # Use a named volume for persistent MLflow data
    volumes:
      - ./mlruns:/app/mlruns
      - ./mlflow.db:/app/mlflow.db

# Define the named volume for MLflow persistence
volumes:
  mlflow_data:
    driver: local
